<!DOCTYPE html>
<html>
<body>
<p>Ethan Goldfarb<br>
ethankgoldfarb@gmail.com</p>

<p>here's a list of the papers I've been reading recently:<br>

2023:

<a href="https://www.google.com/url?q=https://arxiv.org/abs/2301.11325&usg=AOvVaw3GOteWW3RR6wZ6mUswZUvs">[2301.11325] MusicLM: Generating Music From Text</a><br>
<a href="https://www.google.com/url?q=https://arxiv.org/pdf/2006.11477.pdf&usg=AOvVaw1Gpl5_Mr79qIMQzwseS6qI">wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations</a><br>
<a href="https://arxiv.org/pdf/2205.11487.pdf">Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding</a><br>
<a href="https://arxiv.org/pdf/2211.01324.pdf">eDiff-I: Text-to-Image Diffusion Models with an Ensemble of Expert Denoisers</a><br>
<a href="https://arxiv.org/pdf/2112.10752.pdf">High-Resolution Image Synthesis with Latent Diffusion Models</a><br>
<a href="https://arxiv.org/pdf/2105.05233.pdf">Diffusion Models Beat GANs on Image Synthesis</a><br>
<a href="https://arxiv.org/pdf/1804.08838.pdf">Measuring the Intrinsic Dimension of Objective Landscapes</a><br>
<a href="https://arxiv.org/pdf/2103.05247">Pretrained Transformers as Universal Computation Engines</a><br>
<a href="https://arxiv.org/pdf/2202.05607.pdf">Online Decision Transformer</a><br>

</p>
</body>
</html>
